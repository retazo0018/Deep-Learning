{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Minimal_example_with_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/retazo0018/Deep-Learning/blob/master/Minimal_example_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc-7wyrBJUj_",
        "colab_type": "text"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRBRg3lTJOk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ahdFosJ0qm",
        "colab_type": "text"
      },
      "source": [
        "# Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uyzyt35JyNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observations = 1000\n",
        "xs = np.random.uniform(low=-10,high=10,size=(observations,1))\n",
        "zs = np.random.uniform(-10,10,(observations,1))\n",
        "generated_inputs = np.column_stack((xs,zs))\n",
        "noise = np.random.uniform(-1,1,(observations,1))\n",
        "generated_targets = 2*xs - 3*zs + 5 +noise\n",
        "\n",
        "# Main step in data preprocessing in Tensor Flow\n",
        "# To have the data in tensors so as to better computation by TF\n",
        "# One solution is to save the file in .npz file format which is the numpy's file type that stores n-dimensional arrays\n",
        "# Tensors can be represented in n dimensional arrays\n",
        "# data - > preprocess -> save in .npz\n",
        "np.savez('TF_intro', inputs=generated_inputs,targets=generated_targets) # We want a format that can store the information in tensors\n",
        "# 'TF_intro is the file name\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MME4L5r5Mbdl",
        "colab_type": "text"
      },
      "source": [
        "# Solving using Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JXL3KfSMehV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = np.load('TF_intro.npz') # its good to get used to loading your data from NPZs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFSMKV1atbA",
        "colab_type": "text"
      },
      "source": [
        "##### Understanding why is verbose parameter?\n",
        "* verbose = 1 (silent)\n",
        "* verbose = 2 (stands for progress bar)\n",
        "* verbose = 3 (stands for 1 line per epoch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dojh4RQJOYYO",
        "colab_type": "code",
        "outputId": "f941a6d3-34f0-4567-acad-88b26fca0005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_size = 2 # two input variables (xs,zs)\n",
        "output_size = 1 # only one output\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(\n",
        "                                output_size,\n",
        "                                kernel_initializer = tf.random_uniform_initializer(minval=-0.1,maxval=0.1),\n",
        "                                bias_initializer = tf.random_uniform_initializer(minval=-0.1,maxval=0.1)\n",
        "                             )\n",
        "]) \n",
        "# sequential funciton specifies how the model will be laid down ('stacks layers')\n",
        "# Linear combination + output = layer\n",
        "# output = np.dot(inputs,weights) + bias\n",
        "# tf.keras.layers.Dense(outputsize, kernel_initializer, bias_initializer) takes the inputs provided to the model and calculates the dot product of the inputs and the weights and adds the bias also applies the activation funciton if any\n",
        "\n",
        "# model.compile(optimizer,loss) configures the model for training\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
        "model.compile(optimizer = custom_optimizer, loss='mean_squared_error') \n",
        "\n",
        "# model.fit(inputs,targets) fits(trains) the model\n",
        "# epochs - iteration over full data set\n",
        "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f98ca33cc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JIStr9eQMen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 2 # two input variables (xs,zs)\n",
        "output_size = 1 # only one output\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(\n",
        "                                output_size,\n",
        "                                kernel_initializer = tf.random_uniform_initializer(minval=-0.1,maxval=0.1),\n",
        "                                bias_initializer = tf.random_uniform_initializer(minval=-0.1,maxval=0.1)\n",
        "                             )\n",
        "]) \n",
        "# sequential funciton specifies how the model will be laid down ('stacks layers')\n",
        "# Linear combination + output = layer\n",
        "# output = np.dot(inputs,weights) + bias\n",
        "# tf.keras.layers.Dense(outputsize, kernel_initializer, bias_initializer) takes the inputs provided to the model and calculates the dot product of the inputs and the weights and adds the bias also applies the activation funciton if any\n",
        "\n",
        "# model.compile(optimizer,loss) configures the model for training\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
        "model.compile(optimizer = custom_optimizer, loss='mean_squared_error') \n",
        "\n",
        "# model.fit(inputs,targets) fits(trains) the model\n",
        "# epochs - iteration over full data set\n",
        "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmLJTvapbNi0",
        "colab_type": "code",
        "outputId": "76446204-7c16-4861-d8fc-63d5cc50a296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_size = 2 # two input variables (xs,zs)\n",
        "output_size = 1 # only one output\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(\n",
        "                                output_size,\n",
        "                                kernel_initializer = tf.random_uniform_initializer(minval=-0.1,maxval=0.1),\n",
        "                                bias_initializer = tf.random_uniform_initializer(minval=-0.1,maxval=0.1)\n",
        "                             )\n",
        "]) \n",
        "# sequential funciton specifies how the model will be laid down ('stacks layers')\n",
        "# Linear combination + output = layer\n",
        "# output = np.dot(inputs,weights) + bias\n",
        "# tf.keras.layers.Dense(outputsize, kernel_initializer, bias_initializer) takes the inputs provided to the model and calculates the dot product of the inputs and the weights and adds the bias also applies the activation funciton if any\n",
        "\n",
        "# model.compile(optimizer,loss) configures the model for training\n",
        "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
        "model.compile(optimizer = custom_optimizer, loss='mean_squared_error') \n",
        "\n",
        "# model.fit(inputs,targets) fits(trains) the model\n",
        "# epochs - iteration over full data set\n",
        "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/100\n",
            "1000/1000 - 0s - loss: 25.7496\n",
            "Epoch 2/100\n",
            "1000/1000 - 0s - loss: 1.2841\n",
            "Epoch 3/100\n",
            "1000/1000 - 0s - loss: 0.4836\n",
            "Epoch 4/100\n",
            "1000/1000 - 0s - loss: 0.3825\n",
            "Epoch 5/100\n",
            "1000/1000 - 0s - loss: 0.3619\n",
            "Epoch 6/100\n",
            "1000/1000 - 0s - loss: 0.3871\n",
            "Epoch 7/100\n",
            "1000/1000 - 0s - loss: 0.3528\n",
            "Epoch 8/100\n",
            "1000/1000 - 0s - loss: 0.4076\n",
            "Epoch 9/100\n",
            "1000/1000 - 0s - loss: 0.3901\n",
            "Epoch 10/100\n",
            "1000/1000 - 0s - loss: 0.3866\n",
            "Epoch 11/100\n",
            "1000/1000 - 0s - loss: 0.3580\n",
            "Epoch 12/100\n",
            "1000/1000 - 0s - loss: 0.4002\n",
            "Epoch 13/100\n",
            "1000/1000 - 0s - loss: 0.3766\n",
            "Epoch 14/100\n",
            "1000/1000 - 0s - loss: 0.3995\n",
            "Epoch 15/100\n",
            "1000/1000 - 0s - loss: 0.3836\n",
            "Epoch 16/100\n",
            "1000/1000 - 0s - loss: 0.3512\n",
            "Epoch 17/100\n",
            "1000/1000 - 0s - loss: 0.3497\n",
            "Epoch 18/100\n",
            "1000/1000 - 0s - loss: 0.3622\n",
            "Epoch 19/100\n",
            "1000/1000 - 0s - loss: 0.3829\n",
            "Epoch 20/100\n",
            "1000/1000 - 0s - loss: 0.3875\n",
            "Epoch 21/100\n",
            "1000/1000 - 0s - loss: 0.3678\n",
            "Epoch 22/100\n",
            "1000/1000 - 0s - loss: 0.3870\n",
            "Epoch 23/100\n",
            "1000/1000 - 0s - loss: 0.4006\n",
            "Epoch 24/100\n",
            "1000/1000 - 0s - loss: 0.3869\n",
            "Epoch 25/100\n",
            "1000/1000 - 0s - loss: 0.4148\n",
            "Epoch 26/100\n",
            "1000/1000 - 0s - loss: 0.4151\n",
            "Epoch 27/100\n",
            "1000/1000 - 0s - loss: 0.3719\n",
            "Epoch 28/100\n",
            "1000/1000 - 0s - loss: 0.3922\n",
            "Epoch 29/100\n",
            "1000/1000 - 0s - loss: 0.4300\n",
            "Epoch 30/100\n",
            "1000/1000 - 0s - loss: 0.3932\n",
            "Epoch 31/100\n",
            "1000/1000 - 0s - loss: 0.3649\n",
            "Epoch 32/100\n",
            "1000/1000 - 0s - loss: 0.3777\n",
            "Epoch 33/100\n",
            "1000/1000 - 0s - loss: 0.3681\n",
            "Epoch 34/100\n",
            "1000/1000 - 0s - loss: 0.3608\n",
            "Epoch 35/100\n",
            "1000/1000 - 0s - loss: 0.3789\n",
            "Epoch 36/100\n",
            "1000/1000 - 0s - loss: 0.3826\n",
            "Epoch 37/100\n",
            "1000/1000 - 0s - loss: 0.3664\n",
            "Epoch 38/100\n",
            "1000/1000 - 0s - loss: 0.3762\n",
            "Epoch 39/100\n",
            "1000/1000 - 0s - loss: 0.3621\n",
            "Epoch 40/100\n",
            "1000/1000 - 0s - loss: 0.3847\n",
            "Epoch 41/100\n",
            "1000/1000 - 0s - loss: 0.3803\n",
            "Epoch 42/100\n",
            "1000/1000 - 0s - loss: 0.4584\n",
            "Epoch 43/100\n",
            "1000/1000 - 0s - loss: 0.3747\n",
            "Epoch 44/100\n",
            "1000/1000 - 0s - loss: 0.3901\n",
            "Epoch 45/100\n",
            "1000/1000 - 0s - loss: 0.3994\n",
            "Epoch 46/100\n",
            "1000/1000 - 0s - loss: 0.3698\n",
            "Epoch 47/100\n",
            "1000/1000 - 0s - loss: 0.3657\n",
            "Epoch 48/100\n",
            "1000/1000 - 0s - loss: 0.3929\n",
            "Epoch 49/100\n",
            "1000/1000 - 0s - loss: 0.4286\n",
            "Epoch 50/100\n",
            "1000/1000 - 0s - loss: 0.3666\n",
            "Epoch 51/100\n",
            "1000/1000 - 0s - loss: 0.3685\n",
            "Epoch 52/100\n",
            "1000/1000 - 0s - loss: 0.3630\n",
            "Epoch 53/100\n",
            "1000/1000 - 0s - loss: 0.3988\n",
            "Epoch 54/100\n",
            "1000/1000 - 0s - loss: 0.3535\n",
            "Epoch 55/100\n",
            "1000/1000 - 0s - loss: 0.4001\n",
            "Epoch 56/100\n",
            "1000/1000 - 0s - loss: 0.3987\n",
            "Epoch 57/100\n",
            "1000/1000 - 0s - loss: 0.3662\n",
            "Epoch 58/100\n",
            "1000/1000 - 0s - loss: 0.3954\n",
            "Epoch 59/100\n",
            "1000/1000 - 0s - loss: 0.3649\n",
            "Epoch 60/100\n",
            "1000/1000 - 0s - loss: 0.3918\n",
            "Epoch 61/100\n",
            "1000/1000 - 0s - loss: 0.3946\n",
            "Epoch 62/100\n",
            "1000/1000 - 0s - loss: 0.3747\n",
            "Epoch 63/100\n",
            "1000/1000 - 0s - loss: 0.3675\n",
            "Epoch 64/100\n",
            "1000/1000 - 0s - loss: 0.3615\n",
            "Epoch 65/100\n",
            "1000/1000 - 0s - loss: 0.3621\n",
            "Epoch 66/100\n",
            "1000/1000 - 0s - loss: 0.4216\n",
            "Epoch 67/100\n",
            "1000/1000 - 0s - loss: 0.4030\n",
            "Epoch 68/100\n",
            "1000/1000 - 0s - loss: 0.3560\n",
            "Epoch 69/100\n",
            "1000/1000 - 0s - loss: 0.3671\n",
            "Epoch 70/100\n",
            "1000/1000 - 0s - loss: 0.3771\n",
            "Epoch 71/100\n",
            "1000/1000 - 0s - loss: 0.3661\n",
            "Epoch 72/100\n",
            "1000/1000 - 0s - loss: 0.3925\n",
            "Epoch 73/100\n",
            "1000/1000 - 0s - loss: 0.3926\n",
            "Epoch 74/100\n",
            "1000/1000 - 0s - loss: 0.3767\n",
            "Epoch 75/100\n",
            "1000/1000 - 0s - loss: 0.3599\n",
            "Epoch 76/100\n",
            "1000/1000 - 0s - loss: 0.3542\n",
            "Epoch 77/100\n",
            "1000/1000 - 0s - loss: 0.4440\n",
            "Epoch 78/100\n",
            "1000/1000 - 0s - loss: 0.3870\n",
            "Epoch 79/100\n",
            "1000/1000 - 0s - loss: 0.3531\n",
            "Epoch 80/100\n",
            "1000/1000 - 0s - loss: 0.3977\n",
            "Epoch 81/100\n",
            "1000/1000 - 0s - loss: 0.3876\n",
            "Epoch 82/100\n",
            "1000/1000 - 0s - loss: 0.3519\n",
            "Epoch 83/100\n",
            "1000/1000 - 0s - loss: 0.4608\n",
            "Epoch 84/100\n",
            "1000/1000 - 0s - loss: 0.3786\n",
            "Epoch 85/100\n",
            "1000/1000 - 0s - loss: 0.3840\n",
            "Epoch 86/100\n",
            "1000/1000 - 0s - loss: 0.3786\n",
            "Epoch 87/100\n",
            "1000/1000 - 0s - loss: 0.3717\n",
            "Epoch 88/100\n",
            "1000/1000 - 0s - loss: 0.3731\n",
            "Epoch 89/100\n",
            "1000/1000 - 0s - loss: 0.3679\n",
            "Epoch 90/100\n",
            "1000/1000 - 0s - loss: 0.4033\n",
            "Epoch 91/100\n",
            "1000/1000 - 0s - loss: 0.3997\n",
            "Epoch 92/100\n",
            "1000/1000 - 0s - loss: 0.4063\n",
            "Epoch 93/100\n",
            "1000/1000 - 0s - loss: 0.4029\n",
            "Epoch 94/100\n",
            "1000/1000 - 0s - loss: 0.4690\n",
            "Epoch 95/100\n",
            "1000/1000 - 0s - loss: 0.3726\n",
            "Epoch 96/100\n",
            "1000/1000 - 0s - loss: 0.3717\n",
            "Epoch 97/100\n",
            "1000/1000 - 0s - loss: 0.3753\n",
            "Epoch 98/100\n",
            "1000/1000 - 0s - loss: 0.3698\n",
            "Epoch 99/100\n",
            "1000/1000 - 0s - loss: 0.3863\n",
            "Epoch 100/100\n",
            "1000/1000 - 0s - loss: 0.3802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f98ca2818d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl1M5RIIcK7K",
        "colab_type": "text"
      },
      "source": [
        "# Extract weight and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xomgxRHqcNQV",
        "colab_type": "code",
        "outputId": "1217fe92-22e1-47cf-f90e-71aae9fac8cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.layers[0].get_weights()\n",
        "# since we have only 1 layer , layer[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 1.9280474],\n",
              "        [-2.9362202]], dtype=float32), array([5.012492], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWGrm1NncYLN",
        "colab_type": "code",
        "outputId": "714288e0-25e9-422b-e78d-a8354abd429b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "weights = model.layers[0].get_weights()[0]\n",
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.9280474],\n",
              "       [-2.9362202]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAKeh-TZchCC",
        "colab_type": "code",
        "outputId": "56f08139-84ea-4619-f781-1f9245622e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bias = model.layers[0].get_weights()[1]\n",
        "bias"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.012492], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqISH86fc5eY",
        "colab_type": "text"
      },
      "source": [
        "# Extract the outputs (make predictions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpJGa_eTc_V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.predict_on_batch(data) calculated outputs on given inputs\n",
        "model.predict_on_batch(training_data['inputs'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6pjGx6We91o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict_on_batch(training_data['inputs']).round(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0EWEHWqfB2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data['targets'].round(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGlL7MgEfsIi",
        "colab_type": "text"
      },
      "source": [
        "# Ploting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPWsxK2Efv14",
        "colab_type": "code",
        "outputId": "aa3ed229-968f-444e-97e6-8c4c7b62d554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data['targets']))\n",
        "plt.xlabel('outputs')\n",
        "plt.ylabel('targets')\n",
        "plt.show()\n",
        "# inference - if the obtained plot matches 45 degree plot, model is of high accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRcNoYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}