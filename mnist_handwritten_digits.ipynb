{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/retazo0018/Deep-Learning/blob/master/mnist_handwritten_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi2fLvevi5te",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aes8WSiBvxCD",
        "colab_type": "code",
        "outputId": "8d148d53-dda8-475f-c575-6db9da7ef04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# mnist - handwritten digit database\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-SLpNerGBgz",
        "colab_type": "text"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZh-Zz4pwgSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.enable_eager_execution()\n",
        "\n",
        "mnist_dataset, mnist_info = tfds.load(name='mnist',with_info=True, as_supervised=True)\n",
        "\n",
        "# as_suoervised = True ; loads the data in 2-tuple structure [input,output]\n",
        "# with_info = True, provides the tuple containing info about version, features, No. of samples of the dataset\n",
        "\n",
        "\n",
        "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
        "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
        "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
        "\n",
        "num_test_samples = mnist_info.splits['test'].num_examples \n",
        "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
        "\n",
        "def scale(image,label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image/=255\n",
        "  return image,label\n",
        "\n",
        "scaled_train_and_validation_data = mnist_train.map(scale)\n",
        "# dataset.map(*function*) applies a custom transformation to a given dataset. It takes as input a function which determines the transformation\n",
        "\n",
        "test_data = mnist_test.map(scale)\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
        "\n",
        "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
        "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "train_data = train_data.batch(BATCH_SIZE)\n",
        "# dataset.batch(batch_size) a method that combines the consecutive elements of a dataset into batches\n",
        "validation_data = validation_data.batch(num_validation_samples)\n",
        "test_data = test_data.batch(num_test_samples)\n",
        "\n",
        "validation_inputs, validation_targets = next(iter(validation_data))\n",
        "# iter() created an object which can be iterated one element at a time \n",
        "# next() loads the next element of an iterable object"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF3ifTiqGDra",
        "colab_type": "text"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1erGIbJwgUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imput_size = 784 # 28*28\n",
        "output_size = 10\n",
        "input_size = 50\n",
        "hidden_layer_size = 100\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
        "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "                            tf.keras.layers.Dense(output_size,activation='softmax')\n",
        "                            ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqrJZ1IkImso",
        "colab_type": "text"
      },
      "source": [
        "# Chose optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5mV9jK2wgXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# classification problem:\n",
        "# first loss function type\n",
        "# binary_crossentropy\n",
        "# categorical_crossentropy - expects that you have one hot encoded the targets\n",
        "# sparse_categorical_crossentropy - applies one-hot encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJeJJVmNKcWp",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nXWctAOwga2",
        "colab_type": "code",
        "outputId": "0f237e67-4a80-4b49-8862-e349b20d4311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "num_epochs = 5\n",
        "model.fit(train_data, epochs = num_epochs, validation_steps=10, validation_data=(validation_inputs, validation_targets), verbose=2)\n",
        "# At the beginning of each epoch, training loss will be set to zero\n",
        "# The algorithm will iterate over a preset number of batches all from train data\n",
        "# The weights and biases will be updated as many times as there are batches\n",
        "# We will get a value for loss function indicating the training is going\n",
        "# We will also see a training accuracy\n",
        "# At the end of epoch, algorithm will forward propagate the whole validation set\n",
        "# When we reach max number of epochs the training will be over"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "540/540 - 15s - loss: 0.3286 - acc: 0.9080 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
            "Epoch 2/5\n",
            "540/540 - 14s - loss: 0.1360 - acc: 0.9594 - val_loss: 0.1416 - val_acc: 0.9587\n",
            "Epoch 3/5\n",
            "540/540 - 14s - loss: 0.0943 - acc: 0.9720 - val_loss: 0.1219 - val_acc: 0.9652\n",
            "Epoch 4/5\n",
            "540/540 - 14s - loss: 0.0699 - acc: 0.9792 - val_loss: 0.1091 - val_acc: 0.9690\n",
            "Epoch 5/5\n",
            "540/540 - 15s - loss: 0.0541 - acc: 0.9841 - val_loss: 0.1048 - val_acc: 0.9720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6a728125c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHUOjOkSfv3b",
        "colab_type": "text"
      },
      "source": [
        " * Create a Model\n",
        " * Fiddle with hyper parameters\n",
        " * Check validation accuracy\n",
        " * Repeat step 2 until "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xVY4L1bfZtT",
        "colab_type": "text"
      },
      "source": [
        "# Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zhfOaVvKu6O",
        "colab_type": "code",
        "outputId": "f8d980df-786b-4351-97da-ebee2b05aefc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.0831 - acc: 0.9740\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}